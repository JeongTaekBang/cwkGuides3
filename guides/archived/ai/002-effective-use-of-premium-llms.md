# Practical Thoughts on Using o1-pro Effectively

It’s only human, isn’t it? We invest in something pricier than usual and immediately feel the pressure to use it constantly, as if every hour not spent is money wasted. Consider buying a million dollar guitar. Suddenly, you feel compelled to practice every single day, and if you own two or three such guitars, you might start measuring how many hours you must devote to each one just to feel at ease.

The same logic applies to high-end computers. You push them to their limits, monitoring CPU and GPU usage to reassure yourself that you're making the most of the investment. The hardest work you use them for? Needless benchmarking tests.

Now think about top-tier language models. With a premium subscription that costs ten times the standard rate, people might find themselves stretching the tool thin, seeking any reason to justify the expense.

But there’s another way to see this. If you’re always hung up on cost-to-usage ratios, you’ll never choose the best tool for the job in the first place. You’d avoid the finest guitars, the most powerful computers, or premium services, and thus never have them available when you truly need their quality.

Imagine a personal library of a thousand books. Nobody insists on reading each one cover-to-cover just to validate owning them all. The real value lies in having the right resource on hand the moment you need it. The same goes for top-tier tools and services. Their worth becomes clear the instant their quality makes a difference—and that alone can justify the investment.

Rationally, the main priority should be choosing tools that truly excel at their intended purpose, rather than fixating on how often they’re used. Also, don’t fall into the trap of relying on the most compute-intensive, high-end models for every single task—especially when a leaner, more cost-effective option can achieve the same results. For instance, o1 is much faster and just as capable as o1-pro, so there’s no need to keep using o1-pro just because you’ve subscribed to the Pro plan. It’s honestly super slow for what little extra it offers.

Personally, I find that o1 offers an excellent balance between quality, inference speed, and compute cost—even for a Pro plan subscriber. Although it’s slower than GPT-4o, it still outpaces high-end local models running on my Mac Studio M2 Ultra with 192GB RAM. For most tasks, it’s now my go-to default model.

Here's a practical tip: start with GPT-4o or o1 for any task. Only switch to o1-pro when you have a specific reason to believe its enhanced capabilities would provide meaningful benefits over the default models. This approach will save you considerable time while ensuring you leverage the most appropriate model for each task.

견문발검 (見蚊拔劍), an age-old East Asian adage, serves as a fitting reminder: using brute-force solutions for trivial tasks is wasteful and impractical—like drawing a sword just to kill a mosquito. Rationally, it’s better to choose tools that excel at their intended purpose rather than always reaching for top-tier models, especially when a leaner, more cost-effective option fits the bill. Of course, if you’re just trying to show off your Pro plan, that’s another story entirely 🤣