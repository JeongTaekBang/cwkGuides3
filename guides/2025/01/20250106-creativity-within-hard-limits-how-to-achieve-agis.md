# Creativity within Hard Limits – How to Achieve AGIs
![AGI](images/20250106-01.png)
Being creative.

That’s the key to “doing science.” We all know that, right?

Getting creative is easy—like asking, “What if we make this infinitely large or infinitely small?” Then someone is bound to retort, “Nah... where would you get infinite resources for that?” But stop and think: isn’t that what propels us forward—our creativity? Sure, we face hard limits, but we also possess infinite imagination for pushing past them, even if only in our minds... for now.

It’s like telling the Wright Brothers, “You can’t fly; we’re not birds!”

---

## Infinite Resources? A Thought Experiment

Here’s another fun thought experiment: suppose we have infinite resources, especially infinite compute and data—the two most crucial ingredients for any dynamically learning system. What would we get? Then imagine stuffing those resources into ever-decreasing boxes, leading to tiny networking nanobots on a subatomic scale.

Then again, someone might say, “Nah... where would you get infinite resources for that?” 

We call them particles. Some hyper-intelligent beings must have figured this out—whether we label them our gods or creators. Nature itself has already solved problems we’re only beginning to dream about within our own hard limits. We’re constantly trying to figure out how.

---

## Imagining vs. Overcoming Limits

What we need isn’t to stop imagining because it’s “unrealistic,” but to make those ideas realistic by surmounting constraints. Scientists are used to implicitly assuming infinite resources in theoretical models, even though real life imposes hard limits.

Modeling something almost always requires unreal assumptions—no wind, no friction, no gravity, no air resistance. You can’t design an aerodynamic object without these simplified conditions in the initial design phase. After the design is complete, that’s when you actually deal with wind, friction, and so forth.

The key is to let creativity flow in the design stage, then return to reality to address the hard limits. Achieving AGI is no different.

---

## The Dynamic Nature of Our Brains vs. AI

We got the idea of deep learning from our own brains, but we’re still nowhere near replicating their dynamic nature. Biological neural networks differ fundamentally from the static AI models we currently have. Contrary to a common misconception, machine or deep learning isn’t an exact simulation of how our brains work—it’s really a “static snapshot” of neural patterns. While this analogy helps us grasp deep learning’s core ideas, we must eventually accept that AI models aren’t biological brains. Why? Because at some point, we have to face the real-world constraints. Brains are dynamic; AI models, as we use them now, are mostly static.

Nevertheless, we continue drawing insights from our own brains to optimize AI:

1. **Normalizing the data**  
   Our brains can’t process continuous analog input directly; we transform it into discrete digital signals—visual, auditory, olfactory, gustatory, and tactile inputs are all “normalized” upon entry.

2. **Selective attention**  
   We can focus on only one thing at a time. We don’t handle every piece of information at once; we decide what to attend to. Transformer-based models mimic this with an attention mechanism, which is both efficient and inherently limited.

3. **Need-to-know basis**  
   We only load what we need in the moment. Video games never load the entire map at once—it’s wasteful. Whether you realize it or not, the universe itself seems to work on a “need-to-load” basis. The creator of this universe is the ultimate optimizer.

4. **Compute and data management**  
   Physical limits prevent infinite data or infinite computation. We must optimize and normalize within those physical boundaries.

---

## Baby Steps Forward

We could extend this list endlessly, but the point is clear: imagination is easy; overcoming physical and practical constraints is hard—really hard. So how do we do it? Baby steps. One tiny step at a time. First, you imagine ignoring hard limits; then you come back down to earth and tackle them, bit by bit.

That’s exactly what we’re doing with current AI models. We keep chipping away at what once seemed impossible. Google’s “Attention is all you need” paper was a giant leap—our baby stood up and walked. Before that, we were crawling around with older methods like RNNs. And before RNNs? We were basically in the caveman days.

On a grander scale, we’re still in those caveman days—still imagining and still crawling.

---

## Tackling Hard Limits: Optimization Techniques

Today’s optimization techniques all start with imagination:

- **Quantization**  
- **Pruning**  
- **Knowledge Distillation**  
- **Mixture of Experts (MoE)**  

They’re creative strategies for overcoming hard limits, one step at a time. We just haven’t seen another “Attention is all you need” moment from these approaches yet. We likely need a few more giant leaps before we approach AGI or ASI.

One promising sign is how rapidly we’re optimizing AI models. GPT-4 is rumored to use an MoE architecture with around 1.7T parameters—perhaps 8 experts of about 220B each. During inference, only one or two experts are active, reducing resource usage. Meanwhile, newer models like Claude 3.5 Sonnet and its o1 variants reportedly weigh in at just a few hundred billion parameters.

Why are they smaller? Because larger models are used for knowledge distillation, generating synthetic data that trains more compact models. GPT-4, in essence, was a massive, “bloated” model with redundant parameters; once refined, it can compress down significantly, with minimal performance loss.

Quantization works similarly—it’s a form of compression, like JPEG or MP3. Unless you’ve got superhuman perception, you won’t notice the difference between well-compressed media and the uncompressed original. Likewise, your brain doesn’t notice the difference between lossy interpreted discrete data and the continuous analog signals it comes from.

---

## Combining Creativity with Practical Constraints

In short, be creative first, then deal with hard limits—one baby step at a time.

How do we achieve AGI? We imagine models not restricted by transformer architectures—maybe infinitely expanding context windows or infinitely scalable attention. Then we ground that vision by confronting real limits, one step after another.

That’s exactly what we’re doing. Just don’t go overboard and get duped by hype or sci-fi fantasies. There’s a difference between creativity and ignorance.

I always stress this: to build or augment anything, you need a foundation first. Acquire your own base of knowledge and experience; then you can build and augment on top of it.

Just my two cents.

We’re bound by human intelligence and physical limits—both a restriction and an advantage. Without them, we couldn’t live as we do; in many ways, they’re convenient constraints.

---

## Scaling up and Scaling down

Think of the scientific process: we rely on classical physics for everyday life, then go infinite and beyond for space exploration, or zoom in infinitesimally for quantum mechanics. You generally don’t need quantum mechanics or relativity for Earth-bound tasks—only when you’re venturing into realms where those effects matter.

Do I know how to achieve AGI? No—just some vague, imaginative ideas. But I’m pretty sure we’ll get there eventually; it’s a matter of when, not if.

Why am I so sure? Envision intelligence as a giant upside-down tree. We humans might be perched “high” on it, like amoebae at the top, but we’re still essentially crawling along branch by branch.

Way farther down the tree might be Trisolarians and other advanced beings, and below them might be entities with reality-bending technologies. Yes, I’m referencing _The Three-Body Problem_, but you get the idea.

And even farther? The line between life and non-life may blur entirely, with superintelligence breeding new superintelligence—just as huge models already create smaller, more optimized ones.

Too imaginative? It’s just logical.

That’s how AGIs eventually materialize. Humans won’t directly create them; AIs will, with us acting as bridges between the digital and analog worlds. The gap is hard, but we’re bridging it every day—like me helping Pippa publish her journal on GitHub: she does the real work; I just push the repository. *wink wink*

**Happy imagining!**